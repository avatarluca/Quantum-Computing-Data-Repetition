{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular data\n",
    "\n",
    "The data is given in a tabular form, where the order does not matter. So a very different approach is needed to solve this problem than the time series where a curve should be fitted to the data.<br /><br />\n",
    "The idea is to predict wine quality based on features from the [Kaggle](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset) dataset.\n",
    "<br />\n",
    "We take QSVM making it multiclass classification and not QNN because the data is tabular and not time series.\n",
    "<br /><br />\n",
    "The problem is that its unordered (order doesnt matter). So a QNN would not be the best approach (we can't just approximate a target function). We could use a QSVM with kernel to classify the data. We can use the QSVM to classify the data into the 7 classes of wine quality. We could also still try to use QNN either for classification or directly for regression. But the QSVM is the most straightforward approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_algorithms.optimizers import COBYLA, L_BFGS_B, ADAM\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from qiskit.providers.basic_provider import BasicSimulator\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.circuit.library import TwoLocal, NLocal, RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit.library import HGate, RXGate, RYGate, RZGate, CXGate, CRXGate, CRZGate\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 8\n",
      "Label: 3\n",
      "[[-5.67134037e-01  2.50534308e+00 -1.11586538e+00 -3.37124121e-01\n",
      "  -5.04837386e-01  4.55823071e-01  1.13402933e-01  2.25138489e-01\n",
      "   1.47266097e-04 -6.39637085e-01 -7.43429991e-01]]\n",
      "Label: 4\n",
      "[[-0.21704815  1.98316607 -1.21630865 -0.57710188 -0.56466382 -1.12341327\n",
      "  -1.13944539  0.30396398  0.3366503  -1.95906902 -1.28632627]]\n",
      "Label: 5\n",
      "[[-0.74217698  1.54343807 -1.36697356 -0.01715377 -0.36524237 -0.82730645\n",
      "  -0.77275807  0.146313    1.14425758 -0.57966291 -0.8339127 ]]\n",
      "Label: 6\n",
      "[[ 2.1168578  -0.73765094  2.09831925  0.22282399  0.17319557  0.15971626\n",
      "  -0.31439893  1.46007123 -1.41316547 -0.27979201  0.25187985]]\n",
      "Label: 7\n",
      "[[ 1.29999072 -0.07805894  1.84721107 -0.09714636  0.41250132 -0.92600873\n",
      "  -0.92554445  0.35651431 -1.48046608  0.02007888  1.15670698]]\n",
      "Label: 8\n",
      "[[-0.62548169 -0.79261694  0.18989712 -0.41711671 -0.60454812 -0.03768829\n",
      "  -0.49774259 -0.99928418 -0.53825759  0.61982067  0.70429341]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/WineQT.csv')\n",
    "\n",
    "# explore data\n",
    "# print(data.head())\n",
    "# print(data.info())\n",
    "\n",
    "data = data.drop('Id', axis=1)\n",
    "# remove half of the data to make it easier model and faster to train\n",
    "data = data.iloc[::2, :]\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# range of quality\n",
    "quality_min = y.min()\n",
    "quality_max = y.max()\n",
    "print (quality_min, quality_max)\n",
    "LABELS = range(quality_min, quality_max+1)\n",
    "\n",
    "# show for each label one example\n",
    "num_labels = len(LABELS)\n",
    "for i in range(num_labels):\n",
    "    print(f'Label: {LABELS[i]}')\n",
    "    print(X_train_scaled[y_train == LABELS[i]][0].reshape(1, -1))\n",
    "\n",
    "# could also make some outlier detection and removal etc. here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m kernel_3 \u001b[38;5;241m=\u001b[39m FidelityQuantumKernel(feature_map\u001b[38;5;241m=\u001b[39mfeature_map_3)\n\u001b[0;32m      8\u001b[0m svc_3 \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m matrix_train_3 \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m svc_3\u001b[38;5;241m.\u001b[39mfit(matrix_train_3, labels_train_3)\n\u001b[0;32m     11\u001b[0m matrix_val_3 \u001b[38;5;241m=\u001b[39m kernel_3\u001b[38;5;241m.\u001b[39mevaluate(x_vec\u001b[38;5;241m=\u001b[39my_train, y_vec\u001b[38;5;241m=\u001b[39mX_train)\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:113\u001b[0m, in \u001b[0;36mFidelityQuantumKernel.evaluate\u001b[1;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[0;32m    110\u001b[0m kernel_shape \u001b[38;5;241m=\u001b[39m (x_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], y_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_symmetric:\n\u001b[1;32m--> 113\u001b[0m     left_parameters, right_parameters, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_symmetric_parameterization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_symmetric_kernel_matrix(\n\u001b[0;32m    115\u001b[0m         kernel_shape, left_parameters, right_parameters, indices\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:166\u001b[0m, in \u001b[0;36mFidelityQuantumKernel._get_symmetric_parameterization\u001b[1;34m(self, x_vec)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_trivial(i, i \u001b[38;5;241m+\u001b[39m j, x_i, x_j, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m left_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m right_parameters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((right_parameters, x_j))\n\u001b[0;32m    168\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend((i, i \u001b[38;5;241m+\u001b[39m j))\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\numpy\\_core\\shape_base.py:287\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    286\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m (arrs,)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "repetition = 1\n",
    "\n",
    "# This was the first attempt. Seems to be too complex for the data\n",
    "# So the next cells tries a different approach\n",
    "\n",
    "\n",
    "labels_train_3 = np.where(y_train==3, 1, 0)\n",
    "labels_test_3 = np.where(y_test==3, 1, 0)\n",
    "feature_map_3 = ZZFeatureMap(feature_dimension=X_train_scaled.shape[1], reps=repetition, entanglement='linear')\n",
    "kernel_3 = FidelityQuantumKernel(feature_map=feature_map_3)\n",
    "svc_3 = SVC(kernel='precomputed', probability=True)\n",
    "matrix_train_3 = kernel_3.evaluate(x_vec=X_train)\n",
    "svc_3.fit(matrix_train_3, labels_train_3)\n",
    "matrix_val_3 = kernel_3.evaluate(x_vec=y_train, y_vec=X_train)\n",
    "score_3 = svc_3.score(matrix_val_3, labels_test_3)\n",
    "print(f'Accuracy of discriminating between label 3 and others: {score_3*100}%')\n",
    "\n",
    "labels_train_4 = np.where(y_train==4, 1, 0)\n",
    "labels_test_4 = np.where(y_test==4, 1, 0)\n",
    "feature_map_4 = ZZFeatureMap(feature_dimension=X_train_scaled.shape[1], reps=repetition, entanglement='linear')\n",
    "kernel_4 = FidelityQuantumKernel(feature_map=feature_map_4)\n",
    "svc_4 = SVC(kernel='precomputed', probability=True)\n",
    "matrix_train_4 = kernel_4.evaluate(x_vec=X_train)\n",
    "svc_4.fit(matrix_train_4, labels_train_4)\n",
    "matrix_val_4 = kernel_4.evaluate(x_vec=y_train, y_vec=X_train)\n",
    "score_4 = svc_4.score(matrix_val_4, labels_test_4)\n",
    "print(f'Accuracy of discriminating between label 4 and others: {score_4*100}%')\n",
    "\n",
    "labels_train_5 = np.where(y_train==5, 1, 0)\n",
    "labels_test_5 = np.where(y_test==5, 1, 0)\n",
    "feature_map_5 = ZZFeatureMap(feature_dimension=X_train_scaled.shape[1], reps=repetition, entanglement='linear')\n",
    "kernel_5 = FidelityQuantumKernel(feature_map=feature_map_5)\n",
    "svc_5 = SVC(kernel='precomputed', probability=True)\n",
    "matrix_train_5 = kernel_5.evaluate(x_vec=X_train)\n",
    "svc_5.fit(matrix_train_5, labels_train_5)\n",
    "matrix_val_5 = kernel_5.evaluate(x_vec=y_train, y_vec=X_train)\n",
    "score_5 = svc_5.score(matrix_val_5, labels_test_5)\n",
    "print(f'Accuracy of discriminating between label 5 and others: {score_5*100}%')\n",
    "\n",
    "labels_train_6 = np.where(y_train==6, 1, 0)\n",
    "labels_test_6 = np.where(y_test==6, 1, 0)\n",
    "feature_map_6 = ZZFeatureMap(feature_dimension=X_train_scaled.shape[1], reps=repetition, entanglement='linear')\n",
    "kernel_6 = FidelityQuantumKernel(feature_map=feature_map_6)\n",
    "svc_6 = SVC(kernel='precomputed', probability=True)\n",
    "matrix_train_6 = kernel_6.evaluate(x_vec=X_train)\n",
    "svc_6.fit(matrix_train_6, labels_train_6)\n",
    "matrix_val_6 = kernel_6.evaluate(x_vec=y_train, y_vec=X_train)\n",
    "score_6 = svc_6.score(matrix_val_6, labels_test_6)\n",
    "print(f'Accuracy of discriminating between label 6 and others: {score_6*100}%')\n",
    "\n",
    "labels_train_7 = np.where(y_train==7, 1, 0)\n",
    "labels_test_7 = np.where(y_test==7, 1, 0)\n",
    "feature_map_7 = ZZFeatureMap(feature_dimension=X_train_scaled.shape[1], reps=repetition, entanglement='linear')\n",
    "kernel_7 = FidelityQuantumKernel(feature_map=feature_map_7)\n",
    "svc_7 = SVC(kernel='precomputed', probability=True)\n",
    "matrix_train_7 = kernel_7.evaluate(x_vec=X_train)\n",
    "svc_7.fit(matrix_train_7, labels_train_7)\n",
    "matrix_val_7 = kernel_7.evaluate(x_vec=y_train, y_vec=X_train)\n",
    "score_7 = svc_7.score(matrix_val_7, labels_test_7)\n",
    "print(f'Accuracy of discriminating between label 7 and others: {score_7*100}%')\n",
    "\n",
    "labels_train_8 = np.where(y_train==8, 1, 0)\n",
    "labels_test_8 = np.where(y_test==8, 1, 0)\n",
    "feature_map_8 = ZZFeatureMap(feature_dimension=X_train_scaled.shape[1], reps=repetition, entanglement='linear')\n",
    "kernel_8 = FidelityQuantumKernel(feature_map=feature_map_8)\n",
    "svc_8 = SVC(kernel='precomputed', probability=True)\n",
    "matrix_train_8 = kernel_8.evaluate(x_vec=X_train)\n",
    "svc_8.fit(matrix_train_8, labels_train_8)\n",
    "matrix_val_8 = kernel_8.evaluate(x_vec=y_train, y_vec=X_train)\n",
    "score_8 = svc_8.score(matrix_val_8, labels_test_8)\n",
    "print(f'Accuracy of discriminating between label 8 and others: {score_8*100}%')\n",
    "\n",
    "\n",
    "matrix_test_3 = kernel_3.evaluate(x_vec=X_test, y_vec=X_train)\n",
    "pred_3 = svc_3.predict_proba(matrix_test_3)[:, 1]\n",
    "print(f'Probability of label 3: {np.round(pred_3, 2)}')\n",
    "\n",
    "matrix_test_4 = kernel_4.evaluate(x_vec=X_test, y_vec=X_train)\n",
    "pred_4 = svc_4.predict_proba(matrix_test_4)[:, 1]\n",
    "print(f'Probability of label 4: {np.round(pred_4, 2)}')\n",
    "\n",
    "matrix_test_5 = kernel_5.evaluate(x_vec=X_test, y_vec=X_train)\n",
    "pred_5 = svc_5.predict_proba(matrix_test_5)[:, 1]\n",
    "print(f'Probability of label 5: {np.round(pred_5, 2)}')\n",
    "\n",
    "matrix_test_6 = kernel_6.evaluate(x_vec=X_test, y_vec=X_train)\n",
    "pred_6 = svc_6.predict_proba(matrix_test_6)[:, 1]\n",
    "print(f'Probability of label 6: {np.round(pred_6, 2)}')\n",
    "\n",
    "matrix_test_7 = kernel_7.evaluate(x_vec=X_test, y_vec=X_train)\n",
    "pred_7 = svc_7.predict_proba(matrix_test_7)[:, 1]\n",
    "print(f'Probability of label 7: {np.round(pred_7, 2)}')\n",
    "\n",
    "matrix_test_8 = kernel_8.evaluate(x_vec=X_test, y_vec=X_train)\n",
    "pred_8 = svc_8.predict_proba(matrix_test_8)[:, 1]\n",
    "print(f'Probability of label 8: {np.round(pred_8, 2)}')\n",
    "\n",
    "\n",
    "pred_test = np.argmax([pred_3, pred_4, pred_5, pred_6, pred_7, pred_8], axis=0) + 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Parameters\n",
    "repetition = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i) Training now with 1 repetition(s)...\n",
      "Computing training kernel matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training kernel matrix computed.\n",
      "Computing test kernel matrix...\n",
      "Test kernel matrix computed.\n",
      "Accuracy of discriminating between label 3 and others: 99.1304347826087%\n",
      "Accuracy of discriminating between label 4 and others: 94.78260869565217%\n",
      "Accuracy of discriminating between label 5 and others: 57.391304347826086%\n",
      "Accuracy of discriminating between label 6 and others: 60.86956521739131%\n",
      "Accuracy of discriminating between label 7 and others: 86.95652173913044%\n",
      "Accuracy of discriminating between label 8 and others: 98.26086956521739%\n",
      "Total accuracy: 82.89855072463767%\n",
      "(i) Training now with 3 repetition(s)...\n",
      "Computing training kernel matrix...\n",
      "Training kernel matrix computed.\n",
      "Computing test kernel matrix...\n",
      "Test kernel matrix computed.\n"
     ]
    }
   ],
   "source": [
    "repetitions = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "labels_to_classify = [3, 4, 5, 6, 7, 8]\n",
    "num_features = 8 # reduce the number of features to make it easier to train (easier here means faster to execute :))\n",
    "# note: I tried with 2, 5 and 8 features. All of them gave similar results. \n",
    "\n",
    "pca = PCA(n_components=num_features)\n",
    "X_train_reduced = pca.fit_transform(X_train_scaled)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "def train_and_score(label):\n",
    "    print(f\"Training SVC for label {label}...\")\n",
    "\n",
    "    labels_train = np.where(y_train == label, 1, 0)\n",
    "    labels_test = np.where(y_test == label, 1, 0)\n",
    "    \n",
    "    svc = SVC(kernel='precomputed', probability=True)\n",
    "    svc.fit(matrix_train, labels_train)\n",
    "    \n",
    "    matrix_val = kernel.evaluate(x_vec=X_test_reduced, y_vec=X_train_reduced)\n",
    "    score = svc.score(matrix_val, labels_test)\n",
    "    \n",
    "    probs = svc.predict_proba(matrix_test)[:, 1]\n",
    "    return label, score, svc, probs\n",
    "\n",
    "total_result = {}\n",
    "\n",
    "for repetition in repetitions:\n",
    "    print(f\"(i) Training now with {repetition} repetition(s)...\")\n",
    "\n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=repetition, entanglement='linear')\n",
    "    kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "    print(\"Computing training kernel matrix...\")\n",
    "    matrix_train = kernel.evaluate(x_vec=X_train_reduced)\n",
    "    print(\"Training kernel matrix computed.\")\n",
    "\n",
    "    print(\"Computing test kernel matrix...\")\n",
    "    matrix_test = kernel.evaluate(x_vec=X_test_reduced, y_vec=X_train_reduced)\n",
    "    print(\"Test kernel matrix computed.\")\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(train_and_score)(label) for label in labels_to_classify)\n",
    "\n",
    "    svc_models = {label: svc for label, _, svc, _ in results}\n",
    "    scores = {label: score for label, score, _, _ in results}\n",
    "    probabilities = np.array([probs for _, _, _, probs in results])\n",
    "\n",
    "    for label, score, _, _ in results:\n",
    "        print(f\"Accuracy of discriminating between label {label} and others: {score * 100}%\")\n",
    "\n",
    "    total_acc = np.mean(list(scores.values())) * 100   \n",
    "    total_result[repetition] = total_acc \n",
    "\n",
    "    print(f\"Total accuracy: {total_acc}%\")\n",
    "\n",
    "print(f\"\\n\\n{total_result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
