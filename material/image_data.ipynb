{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data classification (using QSVM)\n",
    "\n",
    "The idea is to make a model which predicts the digits. <br />\n",
    "The data is taken from [MNIST](https://yann.lecun.com/exdb/mnist/) (in lecture with 28x28 pixel images of handwritten digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from qiskit.circuit.library import ZFeatureMap, ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import cm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit.providers.basic_provider import BasicSimulator\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.circuit.library import TwoLocal, NLocal, RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit.library import HGate, RXGate, RYGate, RZGate, CXGate, CRXGate, CRZGate\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits classification 4 and 9 (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/mnist.npz'\n",
    "data = np.load(DATA_PATH)\n",
    "\n",
    "sample_train = data['sample_train']\n",
    "labels_train = data['labels_train']\n",
    "sample_test = data['sample_test']\n",
    "\n",
    "sample_train, sample_val, labels_train, labels_val = train_test_split(\n",
    "    sample_train, labels_train, test_size=0.2, random_state=42)\n",
    "\n",
    "LABELS = [4, 5]\n",
    "\n",
    "ss = StandardScaler()\n",
    "sample_train = ss.fit_transform(sample_train)\n",
    "sample_val = ss.transform(sample_val)\n",
    "sample_test = ss.transform(sample_test)\n",
    "\n",
    "N_DIM = 5\n",
    "pca = PCA(n_components=N_DIM)\n",
    "sample_train = pca.fit_transform(sample_train)\n",
    "sample_val = pca.transform(sample_val)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "mms = MinMaxScaler((-1, 1))\n",
    "sample_train = mms.fit_transform(sample_train)\n",
    "sample_val = mms.transform(sample_val)\n",
    "sample_test = mms.transform(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model (training and evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: Serial\n",
      "Training with repetition rate: 1\n",
      "Precomputed kernel classification test score (using linear): 0.8000\n",
      "Precomputed kernel classification test score (using arcsine): 0.5500\n",
      "Training with repetition rate: 3\n",
      "Precomputed kernel classification test score (using linear): 0.6500\n",
      "Precomputed kernel classification test score (using arcsine): 0.7000\n",
      "Training with repetition rate: 5\n",
      "Precomputed kernel classification test score (using linear): 0.7000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7500\n",
      "Training with repetition rate: 7\n",
      "Precomputed kernel classification test score (using linear): 0.7000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7000\n",
      "Training with repetition rate: 9\n",
      "Precomputed kernel classification test score (using linear): 0.5000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7500\n",
      "Training with repetition rate: 11\n",
      "Precomputed kernel classification test score (using linear): 0.6500\n",
      "Precomputed kernel classification test score (using arcsine): 0.7500\n",
      "Training with repetition rate: 13\n",
      "Precomputed kernel classification test score (using linear): 0.6000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7500\n",
      "Training with repetition rate: 15\n",
      "Precomputed kernel classification test score (using linear): 0.5500\n",
      "Precomputed kernel classification test score (using arcsine): 0.8000\n"
     ]
    }
   ],
   "source": [
    "def linear_encoding(x): return x\n",
    "def arcsine_encoding(x): return np.arcsin(x / (2 * np.pi))\n",
    "\n",
    "repetitions = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "\n",
    "# Note: The featuremap itself has already encoding functions (psi(x) and psi(x,y)).\n",
    "# The first function is just the identity function and therefore aquivalent to the linear encoding.\n",
    "# In this experiment I also tried to encode the data with the arcsine function (next to normal linearencoding) and then put those into the psi functions of the feature map.\n",
    "# ZFeatureMap doesnt have psi(x, y) and therefore only uses linear encoding. \n",
    "# Therefore in the last cell is the best comparison between the linear and arcsine encoding.\n",
    "\n",
    "\n",
    "feature_map = PauliFeatureMap(feature_dimension=N_DIM, paulis=['Z'], reps=1)\n",
    "print(f\"Encoding with PauliFeatureMap\")\n",
    "for r in repetitions:\n",
    "    print(f\"Training with repetition rate: {r}\")\n",
    "    \n",
    "    X_train_reupload_linear = linear_encoding(sample_train) # dont need to repeat (because in feature map already is repeated)\n",
    "    X_train_reupload_arcsine = arcsine_encoding(sample_train) # dont need to repeat (because in feature map already is repeated)\n",
    "    X_test_reupload_linear = linear_encoding(sample_val)\n",
    "    X_test_reupload_arcsine = arcsine_encoding(sample_val)\n",
    "\n",
    "    feature_map.reps = r\n",
    "    quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    # kernel_matrix_linear = quantum_kernel.evaluate(x_vec=X_train_reupload_linear[0], y_vec=X_train_reupload_linear[1]) \n",
    "    # kernel_matrix_arcsine = quantum_kernel.evaluate(x_vec=X_train_reupload_arcsine[0], y_vec=X_train_reupload_arcsine[1])\n",
    "\n",
    "    matrix_train_linear = quantum_kernel.evaluate(x_vec=X_train_reupload_linear)\n",
    "    matrix_val_linear = quantum_kernel.evaluate(x_vec=X_test_reupload_linear, y_vec=X_train_reupload_linear)\n",
    "    matrix_train_arcsine = quantum_kernel.evaluate(x_vec=X_train_reupload_arcsine)\n",
    "    matrix_val_arcsine = quantum_kernel.evaluate(x_vec=X_test_reupload_arcsine, y_vec=X_train_reupload_arcsine)\n",
    "\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(np.asmatrix(matrix_train_linear),\n",
    "                interpolation='nearest', origin='upper', cmap='Blues')\n",
    "    axs[0].set_title(\"training kernel matrix linear\")\n",
    "    axs[1].imshow(np.asmatrix(matrix_val_linear),\n",
    "                interpolation='nearest', origin='upper', cmap='Reds')\n",
    "    axs[1].set_title(\"validation kernel matrix linear\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(np.asmatrix(matrix_train_arcsine),\n",
    "                interpolation='nearest', origin='upper', cmap='Blues')\n",
    "    axs[0].set_title(\"training kernel matrix arcsine\")\n",
    "    axs[1].imshow(np.asmatrix(matrix_val_arcsine),\n",
    "                interpolation='nearest', origin='upper', cmap='Reds')\n",
    "    axs[1].set_title(\"validation kernel matrix arcsine\")\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    svm = SVC(kernel='precomputed')\n",
    "    svm.fit(matrix_train_linear, labels_train)\n",
    "    score_linear = svm.score(matrix_val_linear, labels_val)\n",
    "    svm.fit(matrix_train_arcsine, labels_train)\n",
    "    score_arcsine = svm.score(matrix_val_arcsine, labels_val)\n",
    "\n",
    "    print(f\"Precomputed kernel classification test score (using linear): {score_linear:.4f}\")\n",
    "    print(f\"Precomputed kernel classification test score (using arcsine): {score_arcsine:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding with ZZFeatureMap\n",
      "Training with repetition rate: 1\n",
      "Precomputed kernel classification test score (using linear): 0.5000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7000\n",
      "Training with repetition rate: 3\n",
      "Precomputed kernel classification test score (using linear): 0.6000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7500\n",
      "Training with repetition rate: 5\n",
      "Precomputed kernel classification test score (using linear): 0.7000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7500\n",
      "Training with repetition rate: 7\n",
      "Precomputed kernel classification test score (using linear): 0.5000\n",
      "Precomputed kernel classification test score (using arcsine): 0.7000\n",
      "Training with repetition rate: 9\n",
      "Precomputed kernel classification test score (using linear): 0.5500\n",
      "Precomputed kernel classification test score (using arcsine): 0.7000\n",
      "Training with repetition rate: 11\n",
      "Precomputed kernel classification test score (using linear): 0.6000\n",
      "Precomputed kernel classification test score (using arcsine): 0.6500\n",
      "Training with repetition rate: 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m matrix_train_linear \u001b[38;5;241m=\u001b[39m quantum_kernel\u001b[38;5;241m.\u001b[39mevaluate(x_vec\u001b[38;5;241m=\u001b[39mX_train_reupload_linear)\n\u001b[0;32m     22\u001b[0m matrix_val_linear \u001b[38;5;241m=\u001b[39m quantum_kernel\u001b[38;5;241m.\u001b[39mevaluate(x_vec\u001b[38;5;241m=\u001b[39mX_test_reupload_linear, y_vec\u001b[38;5;241m=\u001b[39mX_train_reupload_linear)\n\u001b[1;32m---> 23\u001b[0m matrix_train_arcsine \u001b[38;5;241m=\u001b[39m \u001b[43mquantum_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_reupload_arcsine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m matrix_val_arcsine \u001b[38;5;241m=\u001b[39m quantum_kernel\u001b[38;5;241m.\u001b[39mevaluate(x_vec\u001b[38;5;241m=\u001b[39mX_test_reupload_arcsine, y_vec\u001b[38;5;241m=\u001b[39mX_train_reupload_arcsine)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mfig, axs = plt.subplots(1, 2, figsize=(10, 5))\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03maxs[0].imshow(np.asmatrix(matrix_train_linear),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mplt.show()\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:114\u001b[0m, in \u001b[0;36mFidelityQuantumKernel.evaluate\u001b[1;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_symmetric:\n\u001b[0;32m    113\u001b[0m     left_parameters, right_parameters, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_symmetric_parameterization(x_vec)\n\u001b[1;32m--> 114\u001b[0m     kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_symmetric_kernel_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     left_parameters, right_parameters, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameterization(x_vec, y_vec)\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:202\u001b[0m, in \u001b[0;36mFidelityQuantumKernel._get_symmetric_kernel_matrix\u001b[1;34m(self, kernel_shape, left_parameters, right_parameters, indices)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_symmetric_kernel_matrix\u001b[39m(\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    194\u001b[0m     kernel_shape: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m     indices: KernelIndices,\n\u001b[0;32m    198\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    Given a set of parameterization, this computes the kernel matrix.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     kernel_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_kernel_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     kernel_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(kernel_shape)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (col, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indices):\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\qiskit_machine_learning\\kernels\\fidelity_quantum_kernel.py:229\u001b[0m, in \u001b[0;36mFidelityQuantumKernel._get_kernel_entries\u001b[1;34m(self, left_parameters, right_parameters)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_circuits_per_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fidelity\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    224\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_map] \u001b[38;5;241m*\u001b[39m num_circuits,\n\u001b[0;32m    225\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_map] \u001b[38;5;241m*\u001b[39m num_circuits,\n\u001b[0;32m    226\u001b[0m         left_parameters,\n\u001b[0;32m    227\u001b[0m         right_parameters,\n\u001b[0;32m    228\u001b[0m     )\n\u001b[1;32m--> 229\u001b[0m     kernel_entries \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfidelities\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# Determine the number of chunks needed\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     num_chunks \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    233\u001b[0m         num_circuits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_circuits_per_job \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    234\u001b[0m     ) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_circuits_per_job\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\site-packages\\qiskit\\primitives\\primitive_job.py:51\u001b[0m, in \u001b[0;36mPrimitiveJob.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultT:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_submitted()\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\lucam\\anaconda3\\envs\\qiskit\\Lib\\threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def linear_encoding(x): return x\n",
    "def arcsine_encoding(x): return np.arcsin(x / (2 * np.pi))\n",
    "\n",
    "repetitions = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=N_DIM, entanglement='linear', reps=1)\n",
    "print(f\"Encoding with ZZFeatureMap\")\n",
    "for r in repetitions:\n",
    "    print(f\"Training with repetition rate: {r}\")\n",
    "    \n",
    "    X_train_reupload_linear = linear_encoding(sample_train) # dont need to repeat (because in feature map already is repeated)\n",
    "    X_train_reupload_arcsine = arcsine_encoding(sample_train) # dont need to repeat (because in feature map already is repeated)\n",
    "    X_test_reupload_linear = linear_encoding(sample_val)\n",
    "    X_test_reupload_arcsine = arcsine_encoding(sample_val)\n",
    "\n",
    "    feature_map.reps = r\n",
    "    quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    # kernel_matrix_linear = quantum_kernel.evaluate(x_vec=X_train_reupload_linear[0], y_vec=X_train_reupload_linear[1]) \n",
    "    # kernel_matrix_arcsine = quantum_kernel.evaluate(x_vec=X_train_reupload_arcsine[0], y_vec=X_train_reupload_arcsine[1])\n",
    "\n",
    "    matrix_train_linear = quantum_kernel.evaluate(x_vec=X_train_reupload_linear)\n",
    "    matrix_val_linear = quantum_kernel.evaluate(x_vec=X_test_reupload_linear, y_vec=X_train_reupload_linear)\n",
    "    matrix_train_arcsine = quantum_kernel.evaluate(x_vec=X_train_reupload_arcsine)\n",
    "    matrix_val_arcsine = quantum_kernel.evaluate(x_vec=X_test_reupload_arcsine, y_vec=X_train_reupload_arcsine)\n",
    "\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(np.asmatrix(matrix_train_linear),\n",
    "                interpolation='nearest', origin='upper', cmap='Blues')\n",
    "    axs[0].set_title(\"training kernel matrix linear\")\n",
    "    axs[1].imshow(np.asmatrix(matrix_val_linear),\n",
    "                interpolation='nearest', origin='upper', cmap='Reds')\n",
    "    axs[1].set_title(\"validation kernel matrix linear\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(np.asmatrix(matrix_train_arcsine),\n",
    "                interpolation='nearest', origin='upper', cmap='Blues')\n",
    "    axs[0].set_title(\"training kernel matrix arcsine\")\n",
    "    axs[1].imshow(np.asmatrix(matrix_val_arcsine),\n",
    "                interpolation='nearest', origin='upper', cmap='Reds')\n",
    "    axs[1].set_title(\"validation kernel matrix arcsine\")\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    svm = SVC(kernel='precomputed')\n",
    "    svm.fit(matrix_train_linear, labels_train)\n",
    "    score_linear = svm.score(matrix_val_linear, labels_val)\n",
    "    svm.fit(matrix_train_arcsine, labels_train)\n",
    "    score_arcsine = svm.score(matrix_val_arcsine, labels_val)\n",
    "\n",
    "    print(f\"Precomputed kernel classification test score (using linear): {score_linear:.4f}\")\n",
    "    print(f\"Precomputed kernel classification test score (using arcsine): {score_arcsine:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding with ZFeatureMap\n",
      "Training with repetition rate: 1\n",
      "Precomputed kernel classification test score (using linear): 0.8000\n",
      "Precomputed kernel classification test score (using arcsine): 0.5500\n",
      "Training with repetition rate: 3\n",
      "Precomputed kernel classification test score (using linear): 0.6500\n",
      "Precomputed kernel classification test score (using arcsine): 0.7000\n",
      "Training with repetition rate: 5\n"
     ]
    }
   ],
   "source": [
    "def linear_encoding(x): return x\n",
    "def arcsine_encoding(x): return np.arcsin(x / (2 * np.pi))\n",
    "\n",
    "repetitions = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "feature_map = ZFeatureMap(feature_dimension=N_DIM, reps=1)\n",
    "print(f\"Encoding with ZFeatureMap\")\n",
    "for r in repetitions:\n",
    "    print(f\"Training with repetition rate: {r}\")\n",
    "    \n",
    "    X_train_reupload_linear = linear_encoding(sample_train) # dont need to repeat (because in feature map already is repeated)\n",
    "    X_train_reupload_arcsine = arcsine_encoding(sample_train) # dont need to repeat (because in feature map already is repeated)\n",
    "    X_test_reupload_linear = linear_encoding(sample_val)\n",
    "    X_test_reupload_arcsine = arcsine_encoding(sample_val)\n",
    "\n",
    "    feature_map.reps = r\n",
    "    quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    # kernel_matrix_linear = quantum_kernel.evaluate(x_vec=X_train_reupload_linear[0], y_vec=X_train_reupload_linear[1]) \n",
    "    # kernel_matrix_arcsine = quantum_kernel.evaluate(x_vec=X_train_reupload_arcsine[0], y_vec=X_train_reupload_arcsine[1])\n",
    "\n",
    "    matrix_train_linear = quantum_kernel.evaluate(x_vec=X_train_reupload_linear)\n",
    "    matrix_val_linear = quantum_kernel.evaluate(x_vec=X_test_reupload_linear, y_vec=X_train_reupload_linear)\n",
    "    matrix_train_arcsine = quantum_kernel.evaluate(x_vec=X_train_reupload_arcsine)\n",
    "    matrix_val_arcsine = quantum_kernel.evaluate(x_vec=X_test_reupload_arcsine, y_vec=X_train_reupload_arcsine)\n",
    "\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(np.asmatrix(matrix_train_linear),\n",
    "                interpolation='nearest', origin='upper', cmap='Blues')\n",
    "    axs[0].set_title(\"training kernel matrix linear\")\n",
    "    axs[1].imshow(np.asmatrix(matrix_val_linear),\n",
    "                interpolation='nearest', origin='upper', cmap='Reds')\n",
    "    axs[1].set_title(\"validation kernel matrix linear\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(np.asmatrix(matrix_train_arcsine),\n",
    "                interpolation='nearest', origin='upper', cmap='Blues')\n",
    "    axs[0].set_title(\"training kernel matrix arcsine\")\n",
    "    axs[1].imshow(np.asmatrix(matrix_val_arcsine),\n",
    "                interpolation='nearest', origin='upper', cmap='Reds')\n",
    "    axs[1].set_title(\"validation kernel matrix arcsine\")\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    svm = SVC(kernel='precomputed')\n",
    "    svm.fit(matrix_train_linear, labels_train)\n",
    "    score_linear = svm.score(matrix_val_linear, labels_val)\n",
    "    svm.fit(matrix_train_arcsine, labels_train)\n",
    "    score_arcsine = svm.score(matrix_val_arcsine, labels_val)\n",
    "\n",
    "    print(f\"Precomputed kernel classification test score (using linear): {score_linear:.4f}\")\n",
    "    print(f\"Precomputed kernel classification test score (using arcsine): {score_arcsine:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
